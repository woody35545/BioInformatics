{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "X_OBwhfQ4Oiv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from os.path import join\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sequence_to_onehot(_datax):\n",
        "  res_list = []\n",
        "  for i in range(len(_datax)):\n",
        "    tmp =list()\n",
        "    mapping = {\"A\":[1., 0., 0., 0.], \"C\": [0., 1., 0., 0.], \"G\": [1., 0., 0., 0.], \"T\":[0., 0., 0., 1.]}\n",
        "    for j in _datax[i]:\n",
        "      tmp.append(mapping[j]  if i in mapping.keys() else [0., 0., 0., 0.]) \n",
        "    res_list.append(np.array(tmp))\n",
        "  res_np = np.array(res_list)\n",
        "  return res_np"
      ],
      "metadata": {
        "id": "-tshrjIv9sj_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data shuffle\n",
        "df_shuffled = pd.read_csv('data.csv').sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# x, y 분류. numpy로 변환 후 1차원으로 reshape, sequence onehot encoding\n",
        "datax = sequence_to_onehot(df_shuffled.iloc[:,[0,]].to_numpy().reshape(-1))\n",
        "datay = df_shuffled.iloc[:,[2,]].to_numpy().reshape(-1)\n"
      ],
      "metadata": {
        "id": "iarQFHEQ5Wza"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(datax.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKBVARUi6vpB",
        "outputId": "90b5e99f-6193-400f-d9b2-765f25235d4c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(242, 5600, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train, Test Split \n",
        "trnx, tstx, trny, tsty = train_test_split(datax, datay, test_size = 0.3, random_state =111)\n",
        "\n",
        "print(f\"Train = {trnx.shape[0]}개, Test = {tstx.shape[0]}개\")\n",
        "print(f\"trnx.shape = {trnx.shape}\")\n",
        "print(f\"tstx.shape = {tstx.shape}\")\n",
        "print(f\"trny.shape = {trny.shape}\")\n",
        "print(f\"tsty.shape = {tsty.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-VdsF73AgpL",
        "outputId": "94c6275a-d200-45e1-9ad0-f1d528cacd68"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train = 169개, Test = 73개\n",
            "trnx.shape = (169, 5600, 4)\n",
            "tstx.shape = (73, 5600, 4)\n",
            "trny.shape = (169,)\n",
            "tsty.shape = (73,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (5600,4,1)\n",
        "cnn_model = models.Sequential()\n",
        "\n",
        "cnn_model.add(layers.Conv2D(16,(2,2), padding='same', input_shape=input_shape))\n",
        "cnn_model.add(layers.BatchNormalization())\n",
        "cnn_model.add(layers.Activation(\"relu\"))\n",
        "cnn_model.add(layers.MaxPooling2D((2,2)))\n",
        "\n",
        "cnn_model.add(layers.Conv2D(16,(2,2), padding='same'))\n",
        "cnn_model.add(layers.BatchNormalization())\n",
        "cnn_model.add(layers.Activation(\"relu\"))\n",
        "cnn_model.add(layers.Dropout(0.2))\n",
        "cnn_model.add(layers.MaxPooling2D((2,2)))\n",
        "\n",
        "cnn_model.add(layers.Flatten())\n",
        "\n",
        "cnn_model.add(layers.Dense(units = 128, activation = \"relu\"))\n",
        "cnn_model.add(layers.Dense(units = 1, activation = \"softmax\"))\n",
        "\n",
        "cnn_model.compile(optimizer = 'Adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "cnn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xt7StZmQh8E",
        "outputId": "cd215a88-f112-4358-9f93-7f47fa59d011"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 5600, 4, 16)       80        \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 5600, 4, 16)      64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 5600, 4, 16)       0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 2800, 2, 16)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 2800, 2, 16)       1040      \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 2800, 2, 16)      64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 2800, 2, 16)       0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 2800, 2, 16)       0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 1400, 1, 16)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 22400)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               2867328   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,868,705\n",
            "Trainable params: 2,868,641\n",
            "Non-trainable params: 64\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "histroy = cnn_model.fit(trnx.reshape(-1,5600,4,1), trny, validation_data = [tstx.reshape(-1,5600,4,1),tsty], batch_size = 100, epochs = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PX_55ZGXfJW",
        "outputId": "04f402ca-42cb-4dc7-eabd-0b061f7078ee"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 5s 3s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 5s 2s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 6s 3s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 4s 2s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 4s 2s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.0000e+00 - accuracy: 0.5266 - val_loss: 0.0000e+00 - val_accuracy: 0.4521\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Performance (Measurement = Accuracy)\n",
        "plt.plot(histroy.history['accuracy'])\n",
        "plt.plot(histroy.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc = 'upper left')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "ZL4fMEUaXvnu",
        "outputId": "ce0e2d84-3d01-43d9-c330-942a7de4e306"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zkYkAtF1biQ8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}